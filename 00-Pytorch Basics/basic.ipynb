{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### torch 基本处理单元"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 返回的数组大小5x4的矩阵\n",
    "torch.Tensor(5, 4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -2.0000e+00,  0.0000e+00, -2.0000e+00],\n",
       "        [ 1.3382e-42,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 0.0000e+00,  1.4013e-45,  1.8754e+28,  2.5382e-09],\n",
       "        [ 1.0622e-05,  1.0254e-11,  2.6610e+23,  1.3002e+22],\n",
       "        [ 2.6584e+23,  2.5202e-09,  8.5764e-07,  8.4274e-07]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 返回的数组大小是5x4的矩阵，初始化是0~1的均匀分布\n",
    "torch.rand(5, 4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.2612, 0.9870, 0.5477, 0.2493],\n",
       "        [0.9043, 0.0477, 0.8788, 0.8793],\n",
       "        [0.5501, 0.6282, 0.4119, 0.1462],\n",
       "        [0.9821, 0.4173, 0.0282, 0.3880],\n",
       "        [0.6697, 0.1608, 0.0459, 0.8412]])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 得到矩阵大小\n",
    "a = torch.rand(5, 4)\n",
    "a.size()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# numpy 类似的返回5x4大小的矩阵\n",
    "np.ones((5, 4))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# numpy 和 torch.Tensor 之间的转换\n",
    "a = torch.rand(5, 4)\n",
    "b = a.numpy()\n",
    "print(b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.41055548 0.4136678  0.40775907 0.9686778 ]\n",
      " [0.7950482  0.7650699  0.29611808 0.39977098]\n",
      " [0.42218822 0.64974487 0.46897334 0.4514438 ]\n",
      " [0.33382428 0.46113443 0.16800797 0.26376712]\n",
      " [0.50063115 0.18332887 0.02761292 0.97288346]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a = np.array([[3, 4], [3, 6]])\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[3, 4],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "运算和numpy类似"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "x = torch.rand(5, 4)\n",
    "y = torch.rand(5, 4)\n",
    "c = 3"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(c * x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1.5380, 2.1645, 1.9965, 0.6107],\n",
      "        [0.1352, 0.2802, 0.2215, 2.1290],\n",
      "        [0.7199, 2.0720, 1.6724, 1.5550],\n",
      "        [2.5734, 2.1738, 0.6306, 0.3496],\n",
      "        [1.2427, 2.8435, 2.2669, 2.9603]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(x + y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7369, 1.6857, 1.2191, 1.0406],\n",
      "        [0.7679, 0.4625, 0.4107, 0.7288],\n",
      "        [0.3484, 1.6693, 1.4730, 0.7803],\n",
      "        [1.4851, 1.0354, 0.9635, 0.2558],\n",
      "        [1.0880, 1.4950, 1.0006, 1.5575]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(x.add(y))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7369, 1.6857, 1.2191, 1.0406],\n",
      "        [0.7679, 0.4625, 0.4107, 0.7288],\n",
      "        [0.3484, 1.6693, 1.4730, 0.7803],\n",
      "        [1.4851, 1.0354, 0.9635, 0.2558],\n",
      "        [1.0880, 1.4950, 1.0006, 1.5575]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 可以直接进行操作改变原对象，x+y或者x.add()并不会改变x，但是x.add_()则会对x进行改变\n",
    "x.add_(y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.7369, 1.6857, 1.2191, 1.0406],\n",
       "        [0.7679, 0.4625, 0.4107, 0.7288],\n",
       "        [0.3484, 1.6693, 1.4730, 0.7803],\n",
       "        [1.4851, 1.0354, 0.9635, 0.2558],\n",
       "        [1.0880, 1.4950, 1.0006, 1.5575]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0.7369, 1.6857, 1.2191, 1.0406],\n",
      "        [0.7679, 0.4625, 0.4107, 0.7288],\n",
      "        [0.3484, 1.6693, 1.4730, 0.7803],\n",
      "        [1.4851, 1.0354, 0.9635, 0.2558],\n",
      "        [1.0880, 1.4950, 1.0006, 1.5575]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "将 torch.Tensor 放到 GPU 上"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 判断一下电脑是否支持GPU\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "a = torch.rand(5, 4)\n",
    "a = a.cuda()\n",
    "print(a)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lh/jg4vwjyn1s13t403ctfwvlz40000gn/T/ipykernel_4371/1517051350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### torch 的自动求导功能\n",
    "torch 和大部分框架一样有着自动求导功能，对象不再是 torch.Tensor，而是torch.autograd.Variable\n",
    "\n",
    "本质上Variable和Tensor没有什么区别，不过Variable会放在一个计算图里面，可以进行前向传播和反向传播以及求导  \n",
    "\n",
    "![1.png](http://upload-images.jianshu.io/upload_images/3623720-1c2694b72e0341ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
    "\n",
    "里面的creator表示通过什么操作得到的这个Variable，grad表示反向传播的梯度"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.autograd import Variable"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# requires_grad 表示是否对其求梯度，默认是False\n",
    "x = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "y = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "z = 2 * x + y + 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 对 x 和 y 分别求导\n",
    "z.backward()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# x 的导数和 y 的导数\n",
    "print('dz/dx: {}'.format(x.grad.data))\n",
    "print('dz/dy: {}'.format(y.grad.data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dz/dx: \n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "dz/dy: \n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 神经网络部分\n",
    "\n",
    "所依赖的主要是 torch.nn 和 torch.nn.functional\n",
    "\n",
    "torch.nn 里面有着所有的神经网络的层的操作，其用来构建网络，只有执行一次网络的运算才执行一次\n",
    "\n",
    "torch.nn.functional 表示的是直接对其做一次向前运算操作"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 基本的网络构建类模板\n",
    "class net_name(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net_name, self).__init__()\n",
    "        # 可以添加各种网络层\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3)\n",
    "        # 具体每种层的参数可以去查看文档\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 定义向前传播\n",
    "        out = self.conv1(x)\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": true
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}